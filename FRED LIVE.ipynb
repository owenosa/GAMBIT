{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0baee073",
   "metadata": {},
   "source": [
    "Economic Regime Forecasting Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231fd36d",
   "metadata": {},
   "source": [
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f71e41ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  10 of 10 completed\n",
      "c:\\Users\\owen.osagiede\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:393: RuntimeWarning: invalid value encountered in log\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "# Define ticker mapping (benchmark + sectors)\n",
    "tickers = {\n",
    "    'GOLD': 'GC=F',         # Gold Futures\n",
    "    'OIL': 'CL=F',          # Crude Oil Futures\n",
    "    'SPGSCI': '^SPGSCI',    # S&P GSCI Index\n",
    "    'SPX': '^GSPC',         # S&P 500\n",
    "    'US02': '^IRX',         # 13-Week Treasury Bill (proxy for US 2Y)\n",
    "    'US10': '^TNX',         # 10-Year Treasury Note Yield\n",
    "    'USDCAD': 'CAD=X',      # USD/CAD\n",
    "    'USDEUR': 'EURUSD=X',   # USD/EUR\n",
    "    'USDJPY': 'JPY=X',      # USD/JPY\n",
    "    'VIX': '^VIX',          # Volatility Index\n",
    "}\n",
    "\n",
    "# Download data\n",
    "raw = yf.download(list(tickers.values()),  start=\"1980-01-01\", group_by='ticker', auto_adjust=True)\n",
    "\n",
    "# Extract only the 'Close' column for each ticker\n",
    "data = pd.DataFrame({symbol: raw[ticker]['Close'] for symbol, ticker in tickers.items()})\n",
    "\n",
    "# Calculate daily log returns\n",
    "daily_returns = np.log(data / data.shift(1)).dropna()\n",
    "\n",
    "# Replace zero values with NaN, then forward-fill\n",
    "daily_returns = daily_returns.mask(daily_returns == 0).ffill()\n",
    "\n",
    "# Compute all rolling 30-day and 60-day correlations for each unique pair\n",
    "rolling_corr_30 = pd.DataFrame(index=daily_returns.index)\n",
    "rolling_corr_60 = pd.DataFrame(index=daily_returns.index)\n",
    "\n",
    "for a, b in combinations(daily_returns.columns, 2):\n",
    "    col_name_30 = f\"{a}_{b}_corr_30\"\n",
    "    col_name_60 = f\"{a}_{b}_corr_60\"\n",
    "    rolling_corr_30[col_name_30] = daily_returns[a].rolling(30).corr(daily_returns[b])\n",
    "    rolling_corr_60[col_name_60] = daily_returns[a].rolling(60).corr(daily_returns[b])\n",
    "\n",
    "# Feature Engineering on Correlations\n",
    "fe_corr_30 = rolling_corr_30.copy()\n",
    "fe_corr_60 = rolling_corr_60.copy()\n",
    "\n",
    "for col in rolling_corr_30.columns:\n",
    "    fe_corr_30[f\"{col}_30d_avg_diff\"] = rolling_corr_30[col].rolling(30).mean() - rolling_corr_30[col]\n",
    "    fe_corr_30[f\"{col}_roc_5\"] = rolling_corr_30[col].pct_change(periods=5)\n",
    "\n",
    "for col in rolling_corr_60.columns:\n",
    "    fe_corr_60[f\"{col}_30d_avg_diff\"] = rolling_corr_60[col].rolling(30).mean() - rolling_corr_60[col]\n",
    "    fe_corr_60[f\"{col}_roc_5\"] = rolling_corr_60[col].pct_change(periods=5)\n",
    "\n",
    "# Compute relative log returns (pairwise difference of rolling means)\n",
    "relative_return_30 = pd.DataFrame(index=daily_returns.index)\n",
    "relative_return_60 = pd.DataFrame(index=daily_returns.index)\n",
    "\n",
    "for a, b in combinations(daily_returns.columns, 2):\n",
    "    col_30 = f\"{a}_{b}_ret_30\"\n",
    "    col_60 = f\"{a}_{b}_ret_60\"\n",
    "    relative_return_30[col_30] = daily_returns[a].rolling(30).mean() - daily_returns[b].rolling(30).mean()\n",
    "    relative_return_60[col_60] = daily_returns[a].rolling(60).mean() - daily_returns[b].rolling(60).mean()\n",
    "\n",
    "# Feature Engineering on Relative Returns\n",
    "fe_ret_30 = relative_return_30.copy()\n",
    "fe_ret_60 = relative_return_60.copy()\n",
    "\n",
    "for col in relative_return_30.columns:\n",
    "    fe_ret_30[f\"{col}_roc_5\"] = relative_return_30[col].pct_change(periods=5)\n",
    "\n",
    "for col in relative_return_60.columns:\n",
    "    fe_ret_60[f\"{col}_roc_5\"] = relative_return_60[col].pct_change(periods=5)\n",
    "\n",
    "# Drop rows with missing values\n",
    "fe_corr_30 = fe_corr_30.dropna()\n",
    "fe_corr_60 = fe_corr_60.dropna()\n",
    "fe_ret_30 = fe_ret_30.dropna()\n",
    "fe_ret_60 = fe_ret_60.dropna()\n",
    "\n",
    "# Merge all features\n",
    "all_features = pd.concat([fe_corr_30, fe_corr_60, fe_ret_30, fe_ret_60], axis=1).dropna()\n",
    "\n",
    "# Apply 3.5-year rolling z-score standardization\n",
    "zscore = lambda x: (x - x.rolling(875).mean()) / x.rolling(875).std()\n",
    "numeric_cols = all_features.select_dtypes(include=[np.number]).columns\n",
    "all_features[numeric_cols] = all_features[numeric_cols].apply(zscore)\n",
    "\n",
    "# Final cleanup: retain only selected stable features\n",
    "selected_features = [\n",
    "    'USDCAD_USDJPY_corr_30',\n",
    "    'USDCAD_USDJPY_ret_60',\n",
    "    'USDJPY_VIX_corr_30',\n",
    "    'GOLD_OIL_corr_60',\n",
    "    'SPX_USDEUR_ret_30',\n",
    "    'US02_USDCAD_corr_60',\n",
    "    'US02_VIX_corr_60'\n",
    "]\n",
    "\n",
    "df_features = all_features[selected_features].dropna()\n",
    "\n",
    "# Create lagged features at 1, 5, and 21-day lags\n",
    "lags = [1, 5, 21]\n",
    "lagged_features = []\n",
    "for lag in lags:\n",
    "    lagged = df_features.shift(lag).add_suffix(f\"_lag{lag}\")\n",
    "    lagged_features.append(lagged)\n",
    "\n",
    "# Combine original and lagged features\n",
    "df_final_features = pd.concat([df_features] + lagged_features, axis=1).dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73908e45",
   "metadata": {},
   "source": [
    "hmm + lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92354f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "✅ Exported LSTM regime predictions to 'predicted_regimes_2021_onward.csv'\n"
     ]
    }
   ],
   "source": [
    "# Predict HMM states using saved model\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "hmm_model = joblib.load(\"Models/Macro_hmm_model.pkl\")\n",
    "hmm_states = hmm_model.predict(df_final_features)\n",
    "df_final_features[\"HMM_State\"] = hmm_states\n",
    "\n",
    "# Load LSTM model and run inference\n",
    "lstm_model = load_model(\"Models/Macro_lstm_regime_model.keras\")\n",
    "\n",
    "lookback = 30\n",
    "x_seq = []\n",
    "dates = []\n",
    "\n",
    "for i in range(lookback, len(df_final_features)):\n",
    "    x_seq.append(df_final_features.iloc[i - lookback:i].values)\n",
    "    dates.append(df_final_features.index[i])\n",
    "\n",
    "x_seq = np.array(x_seq)\n",
    "\n",
    "predicted_probs = lstm_model.predict(x_seq)\n",
    "predicted_classes = np.argmax(predicted_probs, axis=1)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Date\": dates,\n",
    "    \"Macro Regime\": predicted_classes\n",
    "})\n",
    "results.set_index(\"Date\", inplace=True)\n",
    "\n",
    "results.to_csv(\"predicted_regimes_2021_onward.csv\")\n",
    "print(\"✅ Exported LSTM regime predictions to 'predicted_regimes_2021_onward.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4167131b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
