{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ccf6ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import yfinance as yf\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "\n",
    "# --- Macro Loader ---\n",
    "def load_macro_data():\n",
    "    macro_path = os.path.join(\"..\", \"Economic Regime Forecaster\", \"Predicted Macro Regimes.csv\")\n",
    "    df = pd.read_csv(macro_path, parse_dates=[\"Date\"])\n",
    "    df = df[[\"Date\", \"Macro Regime\"]].rename(columns={\"Macro Regime\": \"Macro\"})\n",
    "    return df\n",
    "\n",
    "# --- Volatility Loader ---\n",
    "def add_vol_column(macro_df, ticker):\n",
    "    vol_path = os.path.join(\"..\", \"Volatility Regime Forecaster\", \"Predicted Regimes\", f\"PredictedVol_{ticker}.csv\")\n",
    "    vol_df = pd.read_csv(vol_path, parse_dates=[\"Date\"])\n",
    "    vol_df = vol_df[[\"Date\", \"Vol Regime\"]].rename(columns={\"Vol Regime\": \"Vol\"})\n",
    "    df = pd.merge(macro_df, vol_df, on=\"Date\", how=\"left\")\n",
    "    first_valid_index = df[['Macro', 'Vol']].dropna().index.min()\n",
    "    df = df.loc[first_valid_index:].reset_index(drop=True)\n",
    "    df[\"Vol\"] = df[\"Vol\"].bfill()\n",
    "    return df\n",
    "\n",
    "# --- Security Loader (No Threshold) ---\n",
    "def add_price_column(df, ticker, start_date=None):\n",
    "    if start_date is None:\n",
    "        start_date = df[\"Date\"].min()\n",
    "\n",
    "    price_data = yf.download(ticker + \"=F\", start=start_date, progress=False)\n",
    "\n",
    "    # --- Flatten multi-level structure if needed ---\n",
    "    if isinstance(price_data.columns, pd.MultiIndex):\n",
    "        price_data.columns = price_data.columns.get_level_values(0)\n",
    "\n",
    "    # --- Reset index name (IMPORTANT) ---\n",
    "    price_data.columns.name = None\n",
    "\n",
    "    # --- Reset index to make Date a column ---\n",
    "    price_data = price_data.reset_index()\n",
    "\n",
    "    # --- Drop 'Price' column if it exists ---\n",
    "    if \"Price\" in price_data.columns:\n",
    "        price_data = price_data.drop(columns=[\"Price\"])\n",
    "\n",
    "    # --- Check if 'Close' exists, otherwise fallback to 'Adj Close' ---\n",
    "    if \"Close\" in price_data.columns:\n",
    "        price_col = \"Close\"\n",
    "    elif \"Adj Close\" in price_data.columns:\n",
    "        price_col = \"Adj Close\"\n",
    "    else:\n",
    "        print(f\"⚠️  Warning: Neither 'Close' nor 'Adj Close' found for {ticker}. Skipping this ticker.\")\n",
    "        df[\"Price\"] = np.nan\n",
    "        return df\n",
    "\n",
    "    # --- Select Date + price column ---\n",
    "    price_data = price_data[[\"Date\", price_col]].rename(columns={price_col: \"Price\"})\n",
    "\n",
    "    df = pd.merge(df, price_data, on=\"Date\", how=\"left\")\n",
    "    first_valid_index = df[['Macro', 'Vol', 'Price']].dropna().index.min()\n",
    "    df = df.loc[first_valid_index:].reset_index(drop=True)\n",
    "    df[\"Price\"] = df[\"Price\"].bfill()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# --- Price Data Loader ---\n",
    "def add_price_column(df, ticker, start_date=None):\n",
    "    if start_date is None:\n",
    "        start_date = df[\"Date\"].min()\n",
    "\n",
    "    price_data = yf.download(ticker + \"=F\", start=start_date, progress=False)\n",
    "\n",
    "    # --- If MultiIndex, remove second level (ticker) ---\n",
    "    if isinstance(price_data.columns, pd.MultiIndex):\n",
    "        price_data.columns = price_data.columns.get_level_values(0)\n",
    "\n",
    "    # --- Reset index to get 'Date' as column ---\n",
    "    price_data = price_data.reset_index()\n",
    "\n",
    "    # --- Check if 'Close' exists ---\n",
    "    if \"Close\" not in price_data.columns:\n",
    "        print(f\"⚠️  Warning: No 'Close' price found for {ticker}. Skipping this ticker.\")\n",
    "        df[\"Price\"] = np.nan\n",
    "        return df\n",
    "\n",
    "    price_data = price_data[[\"Date\", \"Close\"]].rename(columns={\"Close\": \"Price\"})\n",
    "\n",
    "    df = pd.merge(df, price_data, on=\"Date\", how=\"left\")\n",
    "    first_valid_index = df[['Macro', 'Vol', 'Price']].dropna().index.min()\n",
    "    df = df.loc[first_valid_index:].reset_index(drop=True)\n",
    "    df[\"Price\"] = df[\"Price\"].bfill()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Enrichment with OHLCV ---\n",
    "def enrich_with_ohlcv(ticker, current_df):\n",
    "    start_date = current_df[\"Date\"].min() - timedelta(days=90)\n",
    "\n",
    "    ohlcv = yf.download(ticker + \"=F\", start=start_date, progress=False)\n",
    "\n",
    "    # --- Flatten MultiIndex if needed ---\n",
    "    if isinstance(ohlcv.columns, pd.MultiIndex):\n",
    "        ohlcv.columns = ohlcv.columns.get_level_values(0)\n",
    "\n",
    "    # --- Reset column names ---\n",
    "    ohlcv.columns.name = None\n",
    "\n",
    "    # --- Reset index to make Date a normal column ---\n",
    "    ohlcv = ohlcv.reset_index()\n",
    "\n",
    "    # --- Drop 'Price' if exists (leftover junk) ---\n",
    "    if \"Price\" in ohlcv.columns:\n",
    "        ohlcv = ohlcv.drop(columns=[\"Price\"])\n",
    "\n",
    "    # --- Only keep necessary columns ---\n",
    "    ohlcv = ohlcv[[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "\n",
    "    return ohlcv\n",
    "\n",
    "\n",
    "# --- Compute AVWAP and Pivot Points ---\n",
    "def compute_avwap_and_pivots(current_df, ohlcv_df):\n",
    "    df = pd.merge(current_df, ohlcv_df, on=\"Date\", how=\"left\")\n",
    "    df[\"30d_high\"] = df[\"Close\"].rolling(window=30, min_periods=1).max()\n",
    "    df[\"AVWAP\"] = float(\"nan\")\n",
    "    cum_pv, cum_v, anchor_index = 0.0, 0.0, None\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if df[\"Close\"].iloc[i] == df[\"30d_high\"].iloc[i]:\n",
    "            anchor_index = i\n",
    "            cum_pv, cum_v = 0.0, 0.0\n",
    "        if anchor_index is not None:\n",
    "            price = df[\"Close\"].iloc[i]\n",
    "            volume = df[\"Volume\"].iloc[i]\n",
    "            cum_pv += price * volume\n",
    "            cum_v += volume\n",
    "            df.at[i, \"AVWAP\"] = cum_pv / cum_v if cum_v != 0 else price\n",
    "\n",
    "    df[\"Base\"] = (df[\"High\"] + df[\"Low\"] + df[\"Close\"]) / 3\n",
    "    df[\"R1\"] = 2 * df[\"Base\"] - df[\"Low\"]\n",
    "    df[\"S1\"] = 2 * df[\"Base\"] - df[\"High\"]\n",
    "    df[\"R2\"] = df[\"Base\"] + (df[\"High\"] - df[\"Low\"])\n",
    "    df[\"S2\"] = df[\"Base\"] - (df[\"High\"] - df[\"Low\"])\n",
    "\n",
    "    start_date = current_df[\"Date\"].min()\n",
    "    df = df[df[\"Date\"] >= start_date].reset_index(drop=True)\n",
    "\n",
    "    # Final clean-up: enforce consistent column order\n",
    "    final_columns = [\"Date\", \"Macro\", \"Vol\", \"Security\", \"Security Proba\", \"Price\", \"AVWAP\", \"Base\", \"R1\", \"R2\", \"S1\", \"S2\"]\n",
    "    df = df[final_columns]\n",
    "\n",
    "    # --- Convert everything except 'Date' to float32 ---\n",
    "    for col in df.columns:\n",
    "        if col != \"Date\":\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype(np.float32)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# --- Master Function to Build and Save All ---\n",
    "def build_and_save_rl_datasets(ticker_list):\n",
    "    macro_df = load_macro_data()\n",
    "\n",
    "    for ticker in ticker_list:\n",
    "        print(f\"Processing {ticker}...\")\n",
    "\n",
    "        df = add_vol_column(macro_df, ticker)\n",
    "        df = add_security_column(df, ticker)\n",
    "        df = add_price_column(df, ticker)\n",
    "        ohlcv_df = enrich_with_ohlcv(ticker, df)\n",
    "        final_df = compute_avwap_and_pivots(df, ohlcv_df)\n",
    "\n",
    "        output_name = f\"RL - {ticker}.csv\"\n",
    "        final_df.to_csv(output_name, index=False, float_format=\"%.5f\")\n",
    "        print(f\"Saved {output_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "93438bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ES...\n",
      "Saved RL - ES.csv\n",
      "Processing CL...\n",
      "Saved RL - CL.csv\n",
      "Processing ZN...\n",
      "Saved RL - ZN.csv\n"
     ]
    }
   ],
   "source": [
    "tickers = [\"ES\", \"CL\", \"ZN\"]  # or whatever you want\n",
    "build_and_save_rl_datasets(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eaed41",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
